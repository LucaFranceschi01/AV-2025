{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c617f4",
   "metadata": {
    "id": "c4c617f4"
   },
   "source": [
    "# Lab 11 (Evaluable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd7ba9",
   "metadata": {
    "id": "abfd7ba9"
   },
   "source": [
    "We work for one of the most popular car buying and selling platforms in the world. From the product team they want to introduce a price recommender for the user based on the qualities of the car they want to sell. They have asked the Data Science team to tackle the challenge including:\n",
    "- An exhaustive analysis of the data of the vehicles introduced in the platform in the past.\n",
    "- The development of a predictive pricing model.\n",
    "- The creation of a streamlit app that allows you to view the results of the analysis and interact with the model.\n",
    "- Adding an explainability tab to the app so that all users can understand why each price is recommended to them.\n",
    "\n",
    "# Practice Information:\n",
    "**Due date:** By end of November, 28th (14h)\n",
    "\n",
    "**Submission procedure:** via Moodle.\n",
    "\n",
    "**Name:** Luca Franceschi\n",
    "\n",
    "**NIA:** 253885"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe7981",
   "metadata": {
    "id": "89fe7981"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d8ddd",
   "metadata": {
    "id": "526d8ddd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "#from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "sns.set_palette(\"icefire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7175d3",
   "metadata": {
    "id": "6a7175d3"
   },
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58033a",
   "metadata": {
    "id": "de58033a",
    "outputId": "41c05dda-4b04-4a14-cab8-79b0af877b71"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"car_ad_display.csv\", encoding = \"ISO-8859-1\", sep=\";\").drop(columns='Unnamed: 0')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4984d56",
   "metadata": {
    "id": "f4984d56"
   },
   "source": [
    "## Data Gathering and Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa22f1",
   "metadata": {
    "id": "1baa22f1",
    "outputId": "6ff4d369-ead2-47e2-c7e7-9acd03d7829b"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4630ab",
   "metadata": {
    "id": "0c4630ab",
    "outputId": "1c85ccb4-e162-40b2-ac9a-54045d4b3ec2"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9920e",
   "metadata": {
    "id": "dfc9920e"
   },
   "source": [
    "#### EX1: How many different entries do we have for the car names column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb9b8d",
   "metadata": {
    "id": "60fb9b8d"
   },
   "source": [
    "**Solution:** for both model and car brand we have 8467 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18626213",
   "metadata": {
    "id": "18626213"
   },
   "source": [
    "#### Let's reduce the number of car names with a cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb7445",
   "metadata": {
    "id": "85eb7445"
   },
   "outputs": [],
   "source": [
    "def shorten_categories(categories, cutoff):\n",
    "    categorical_map = {}\n",
    "    for i in range(len(categories)):\n",
    "        if categories.values[i] >= cutoff:\n",
    "            categorical_map[categories.index[i]] = categories.index[i]\n",
    "        else:\n",
    "            categorical_map[categories.index[i]] = 'Other'\n",
    "    return categorical_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb503567",
   "metadata": {
    "id": "bb503567",
    "outputId": "32293fb0-2aaa-40b5-bd88-300ef20cc499"
   },
   "outputs": [],
   "source": [
    "car_map = shorten_categories(df.car.value_counts(), 10)\n",
    "df['car'] = df['car'].map(car_map)\n",
    "df.car.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a744b",
   "metadata": {
    "id": "559a744b"
   },
   "source": [
    "#### EX2: Do the same with car model feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cdddc",
   "metadata": {
    "id": "e42cdddc",
    "outputId": "632667a5-4799-4ca0-b14d-96e50ba2ae20"
   },
   "outputs": [],
   "source": [
    "# CODE HERE \n",
    "# NOTE: with the same threshold we remove 2/3 of the data aprox\n",
    "\n",
    "model_map = shorten_categories(df.model.value_counts(), 10)\n",
    "df['model'] = df['model'].map(model_map)\n",
    "df.model.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97e340",
   "metadata": {
    "id": "1f97e340"
   },
   "source": [
    "#### EX3: Plot a bar char of the TOP 10 most expensive cars.\n",
    "#### Which is the mean price per car brand?  (for the top 10 most expensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09656115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am taking into account duplicates and different models / bodies for the different brands.\n",
    "# Otherwise we would be showing the brands. Since the problem asked for cars specifically.\n",
    "\n",
    "tmp = df.groupby(['car', 'model', 'body']).mean(numeric_only=True).sort_values('price', ascending=False)\n",
    "tmp = tmp.reset_index()\n",
    "tmp['index'] = tmp.agg(lambda x: f'{x['car']}: {x['model']} ({x['body']})', axis=1)\n",
    "tmp = tmp.reset_index(drop=True)\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05260b92",
   "metadata": {
    "id": "05260b92",
    "outputId": "93bf3a03-436d-4f77-aefe-f2e991f0a32d"
   },
   "outputs": [],
   "source": [
    "# CODE HERE \n",
    "sns.barplot(tmp[:10], x='price', y='index')\n",
    "plt.title('Top 10 most expensive cars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71588cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby(['car']).mean(numeric_only=True).sort_values('price', ascending=False)\n",
    "tmp = tmp.reset_index()\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d268a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(tmp[:10], x='price', y='car')\n",
    "plt.title('Top 10 most expensive brands on average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96d5ea",
   "metadata": {
    "id": "5f96d5ea"
   },
   "source": [
    "#### Let's analyze each variable distribution (except for car and model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f0b07",
   "metadata": {
    "id": "bb7f0b07",
    "outputId": "95fc5caa-fcaf-437c-e407-9ac6b013da46"
   },
   "outputs": [],
   "source": [
    "# Define the type of plot for each column based on the data type\n",
    "plot_types = {}\n",
    "columns = [x for x in df.columns if x not in [\"car\", \"model\"]]\n",
    "\n",
    "for col in columns:\n",
    "    if df[col].dtype == 'object':  # Categorical columns\n",
    "        plot_types[col] = 'bar'\n",
    "    else:\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values < 10:  # Discrete columns\n",
    "            plot_types[col] = 'bar'\n",
    "        else:  # Continuous columns\n",
    "            plot_types[col] = 'kde'\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (len(columns) + 2) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each column in the dataframe\n",
    "for i, col in enumerate(columns):\n",
    "    ax = axes[i]\n",
    "    if plot_types[col] == 'bar':\n",
    "        # For categorical and discrete data, use a count plot (bar chart)\n",
    "        sns.countplot(x=col, data=df, ax=ax)\n",
    "        ax.set_title(f'Count Plot of {col}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Counts')\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    else:\n",
    "        # For continuous data, use a density plot\n",
    "        sns.kdeplot(df[col], ax=ax, fill=True)\n",
    "        ax.set_title(f'Density Plot of {col}')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Density')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297709b",
   "metadata": {
    "id": "c297709b",
    "outputId": "1df7eb77-93b5-4bf9-9e29-a850deec6e7e"
   },
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = (len(numeric_columns) + 2) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.boxplot(y=col, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}')\n",
    "\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ed4d9",
   "metadata": {
    "id": "251ed4d9"
   },
   "source": [
    "#### Let's analyze each variable behaviour with respect to the target (price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a6008",
   "metadata": {
    "id": "cc7a6008",
    "outputId": "766260c0-1260-46d4-9d06-661ae22428e0"
   },
   "outputs": [],
   "source": [
    "target = 'price'\n",
    "features = [x for x in df.columns if x not in [\"car\", \"model\", target]]\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (len(features) + 2) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each feature against the target variable in the dataframe\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    if df[feature].dtype == 'object' or df[feature].nunique() < 10:\n",
    "        # For categorical data, use a boxplot or violin plot\n",
    "        sns.boxplot(x=feature, y=target, data=df, ax=ax)\n",
    "    else:\n",
    "        # For numerical data, use a scatter plot\n",
    "        sns.scatterplot(x=feature, y=target, data=df, ax=ax)\n",
    "    ax.set_title(f'{feature} vs {target}')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b7d25",
   "metadata": {
    "id": "c89b7d25"
   },
   "source": [
    "#### As we see, there are many outliers in the features and in the target data.\n",
    "#### Let's get rid of outliers in the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186401d",
   "metadata": {
    "id": "a186401d",
    "outputId": "1934ded5-a398-4f06-c0ef-338cf8bce8fd"
   },
   "outputs": [],
   "source": [
    "#Let's filter the prices between 1K and 100K\n",
    "df = df[df[\"price\"] <= 100000]\n",
    "df = df[df[\"price\"] >= 1000]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.kdeplot(x=\"price\", data=df, fill=True)\n",
    "ax.set_title(f'Count Plot of Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6443f",
   "metadata": {
    "id": "d7f6443f"
   },
   "source": [
    "#### Let's get rid of outliers in the rest of the numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0095b",
   "metadata": {
    "id": "37d0095b"
   },
   "outputs": [],
   "source": [
    "#Let's filter the mileage over 600\n",
    "df = df[df[\"mileage\"] <= 600]\n",
    "\n",
    "#Let's filter the engV over 7.5\n",
    "df = df[df[\"engV\"] <= 7.5]\n",
    "\n",
    "#Let's filter the year over 1975\n",
    "df = df[df[\"year\"] >= 1975]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458467f8",
   "metadata": {
    "id": "458467f8"
   },
   "source": [
    "#### Check how the behaviour of the features with the target has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58126915",
   "metadata": {
    "id": "58126915",
    "outputId": "54b9ebfa-ac32-4252-8c82-f5c66d6fe34f"
   },
   "outputs": [],
   "source": [
    "target = 'price'\n",
    "features = [x for x in df.columns if x not in [\"car\", \"model\", target]]\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (len(features) + 2) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each feature against the target variable in the dataframe\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    if df[feature].dtype == 'object' or df[feature].nunique() < 10:\n",
    "        # For categorical data, use a boxplot or violin plot\n",
    "        sns.boxplot(x=feature, y=target, data=df, ax=ax)\n",
    "    else:\n",
    "        # For numerical data, use a scatter plot\n",
    "        sns.scatterplot(x=feature, y=target, data=df, ax=ax)\n",
    "    ax.set_title(f'{feature} vs {target}')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0d7db",
   "metadata": {},
   "source": [
    "#### EX4: Which of the features do you predict would be more important for estimating the price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b091f0",
   "metadata": {},
   "source": [
    "**Solution:** Because of the above plots, the features that seem to have the most inter-feature variance (i.e.: different classes in the same feature seem to behave very differently), therefore are most likely important to predict the price are:\n",
    "\n",
    "- Year\n",
    "- EngV\n",
    "- Mileage\n",
    "- Drive\n",
    "- (Not seen in above plots, but seen in exercise before) Brand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdafb5",
   "metadata": {
    "id": "53cdafb5"
   },
   "source": [
    "#### EX5: After all changes, How many rows are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c02b3",
   "metadata": {
    "id": "497c02b3",
    "outputId": "e38b8aa0-b302-4c88-a89e-8e44aa75ea1d"
   },
   "outputs": [],
   "source": [
    "# CODE HERE:\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae0083",
   "metadata": {
    "id": "afae0083"
   },
   "source": [
    "**Solution:** \n",
    "8224 non-null rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986e177",
   "metadata": {
    "id": "9986e177"
   },
   "source": [
    "### Let's prepare the data for model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816b85f",
   "metadata": {
    "id": "3816b85f",
    "outputId": "35109089-c159-4a13-f337-cc81e503d68c"
   },
   "outputs": [],
   "source": [
    "df_original = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28753d37",
   "metadata": {
    "id": "28753d37",
    "outputId": "b7966511-b7e4-4c24-ee14-c8ecca03acb6"
   },
   "outputs": [],
   "source": [
    "#Let's encode the string features:\n",
    "\n",
    "le_car = LabelEncoder()\n",
    "df['car'] = le_car.fit_transform(df['car'])\n",
    "print('*CAR: \\n', df[\"car\"].unique(), '\\n')\n",
    "\n",
    "le_body = LabelEncoder()\n",
    "df['body'] = le_body.fit_transform(df['body'])\n",
    "print('*BODY: \\n', df[\"body\"].unique(), '\\n')\n",
    "\n",
    "le_engType = LabelEncoder()\n",
    "df['engType'] = le_engType.fit_transform(df['engType'])\n",
    "print('*EngType: \\n', df[\"engType\"].unique(), '\\n')\n",
    "\n",
    "le_drive = LabelEncoder()\n",
    "df['drive'] = le_drive.fit_transform(df['drive'])\n",
    "print('*DRIVE: \\n', df[\"drive\"].unique(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec4739",
   "metadata": {
    "id": "d7ec4739",
    "outputId": "ab4ec2e3-f505-40e5-a949-8b847ce71b51"
   },
   "outputs": [],
   "source": [
    "#Encode registration string feature into a int boolean feature\n",
    "yes_l = ['yes', 'YES', 'Yes', 'y', 'Y']\n",
    "df['registration'] = np.where(df['registration'].isin(yes_l), 1, 0)\n",
    "df['registration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191582b6",
   "metadata": {
    "id": "191582b6"
   },
   "outputs": [],
   "source": [
    "# We will drop 'model' feature as there is no simple way to handle that amount of unique values.\n",
    "df = df.drop(columns='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37851ea",
   "metadata": {
    "id": "b37851ea",
    "outputId": "d3b413c2-53de-45d3-9a18-1fe3d830eae1"
   },
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca03eb7",
   "metadata": {},
   "source": [
    "#### EX6: Now that all data is in numeric data type, Plot the correlation matrix among features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe3f93",
   "metadata": {
    "id": "20fe3f93",
    "outputId": "7b70ef83-0fce-4a49-fc78-b24288e25c99"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(6, 5))\n",
    "heatmap = sns.heatmap(corr, vmin=-1, vmax=1, annot=True, cmap='icefire')\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':10});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12275960",
   "metadata": {
    "id": "12275960"
   },
   "source": [
    "#### EX7: Which variables are more correlated with the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ff908",
   "metadata": {
    "id": "a66ff908"
   },
   "source": [
    "**Solution:**\n",
    "\n",
    "More positive correlated: engV, year, drive\n",
    "More negatively correlated: mileage, body (since it's categorical, being *negatively* correlated does not mean anything, but it's correlated.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0797c7",
   "metadata": {
    "id": "8b0797c7"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a11a2",
   "metadata": {
    "id": "074a11a2"
   },
   "outputs": [],
   "source": [
    "#Let's split train and test data\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_test.to_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f15210",
   "metadata": {
    "id": "23f15210"
   },
   "source": [
    "#### Ensure X and Y have the same lenght for both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278334a",
   "metadata": {
    "id": "c278334a",
    "outputId": "e539f5fc-36e0-4f82-832f-20eddfa0534a"
   },
   "outputs": [],
   "source": [
    "print(\"Lenght X_train:\",len(X_train))\n",
    "print(\"Length y_train:\", len(y_train))\n",
    "print(\"Lenght X_test:\",len(X_test))\n",
    "print(\"Length y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f382cf",
   "metadata": {
    "id": "69f382cf"
   },
   "source": [
    "#### Try different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94eeb6",
   "metadata": {
    "id": "8e94eeb6",
    "outputId": "b1e0c3a0-ca3a-4541-dd36-daf76331955d"
   },
   "outputs": [],
   "source": [
    "#Linear Regression:\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "display(linear_reg)\n",
    "\n",
    "y_pred_test = linear_reg.predict(X_test)\n",
    "error = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(\"{:,.02f}\".format(error))\n",
    "# its an error why the dollar lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c308d9",
   "metadata": {
    "id": "b7c308d9",
    "outputId": "c99275b4-1cb6-4ee0-8ba4-7dafc2c747ba"
   },
   "outputs": [],
   "source": [
    "#Random Forest:\n",
    "\n",
    "random_forest_reg = RandomForestRegressor(random_state=0)\n",
    "random_forest_reg.fit(X_train, y_train)\n",
    "display(random_forest_reg)\n",
    "\n",
    "y_pred_test = random_forest_reg.predict(X_test)\n",
    "error = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(\"{:,.02f}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5209055",
   "metadata": {
    "id": "d5209055",
    "outputId": "a563bb0e-e4fc-4e1b-c2d1-8a19eb6b8f44"
   },
   "outputs": [],
   "source": [
    "#XGBoost:\n",
    "\n",
    "lgb_reg = lgb.LGBMRegressor()\n",
    "lgb_reg.fit (X_train, y_train)\n",
    "display(lgb_reg)\n",
    "\n",
    "y_pred_test=lgb_reg.predict(X_test)\n",
    "error = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(\"{:,.02f}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898bd7a2",
   "metadata": {
    "id": "898bd7a2"
   },
   "source": [
    "#### it seems that LightGBM performs better for this use case, so let's continue with the this algorithm grid search for choosing the best parameters (this can take some minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791d99d",
   "metadata": {
    "id": "6791d99d",
    "outputId": "25c8b868-beb8-4650-bac0-9b948df14467"
   },
   "outputs": [],
   "source": [
    "# Add as many parametrers as you want\n",
    "max_depth = [2, 8, 12]\n",
    "n_estimators = [50, 100, 300]\n",
    "learning_rate = [0.1]\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"learning_rate\": learning_rate}\n",
    "\n",
    "lgb_reg = lgb.LGBMRegressor(random_state=42, force_row_wise=True)\n",
    "\n",
    "# Grid Search\n",
    "gs = GridSearchCV(lgb_reg, parameters, scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36412a5b",
   "metadata": {
    "id": "36412a5b",
    "outputId": "f75b5bff-2fa8-4d0a-ee20-e8b595a440e9"
   },
   "outputs": [],
   "source": [
    "lgb_reg = gs.best_estimator_\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = lgb_reg.predict(X_test)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(\"{:,.02f}\".format(error))\n",
    "\n",
    "print(\"The R2_score is:\", r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098659a9",
   "metadata": {
    "id": "098659a9"
   },
   "source": [
    "#### EX8: Test with an invented example (just run the code and answer the questions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1796f9",
   "metadata": {
    "id": "bf1796f9",
    "outputId": "5a632034-9136-47f6-e471-84ee1b2c3a74"
   },
   "outputs": [],
   "source": [
    "A = []\n",
    "Q = [\n",
    "    \"Enter your brand car \"+  str(list(df_original['car'].unique()[:5]))[:-1]+\" , ...]: \",\n",
    "    \"Enter the body category of your car \"+ str(list(df_original['body'].unique()))+': ',\n",
    "    \"Enter the milage: \",\n",
    "    \"Enter the engV (use '.' as decimal): \",\n",
    "    \"Enter the engType \"+ str(list(df_original['engType'].unique()))+': ',\n",
    "    \"Enter if it registered (yes/no): \",\n",
    "    \"Enter the year of the car: \",\n",
    "    \"Enter the drive type of the car \"+ str(list(df_original['drive'].unique()))+': ']\n",
    "\n",
    "for q in Q:\n",
    "    a = input(q)\n",
    "    A.append(a)\n",
    "\n",
    "print(\"Your answers are:\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dd152",
   "metadata": {
    "id": "228dd152",
    "outputId": "c2622e5c-79ac-455e-92e5-ca612b3500f9"
   },
   "outputs": [],
   "source": [
    "X_sample = np.array([A])\n",
    "\n",
    "# Apply the encoder and data type corrections:\n",
    "X_sample[:, 0] = str(X_sample[:, 0][0] if X_sample[:, 0][0] in list(df_original['car'].unique()) else 'Other')\n",
    "X_sample[:, 0] = le_car.transform(X_sample[:,0])\n",
    "X_sample[:, 1] = le_body.transform(X_sample[:,1])\n",
    "X_sample[:, 4] = le_engType.transform(X_sample[:,4])\n",
    "X_sample[:, 5] = int(1 if X_sample[:, 5][0] in yes_l else 0)\n",
    "X_sample[:, 7] = le_drive.transform(X_sample[:,7])\n",
    "\n",
    "X_sample = np.array([[\n",
    "    int(X_sample[0, 0]),\n",
    "    int(X_sample[0, 1]),\n",
    "    int(X_sample[0, 2]),\n",
    "    float(X_sample[0, 3]),\n",
    "    int(X_sample[0, 4]),\n",
    "    int(X_sample[0, 5]),\n",
    "    int(X_sample[0, 6]),\n",
    "    int(X_sample[0, 7])\n",
    "]])\n",
    "\n",
    "print('The encoded array is: ', X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521cec0",
   "metadata": {
    "id": "f521cec0",
    "outputId": "46aa9549-e25a-447f-f975-ec37ff91ce4c"
   },
   "outputs": [],
   "source": [
    "y_pred_sample = lgb_reg.predict(X_sample)\n",
    "print(\"Your car estimated price is: \",\"${:,.02f}\".format(y_pred_sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02203cb1",
   "metadata": {},
   "source": [
    "Which questions??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303234c6",
   "metadata": {
    "id": "303234c6"
   },
   "source": [
    "### Store and read the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f1ca6",
   "metadata": {
    "id": "627f1ca6"
   },
   "outputs": [],
   "source": [
    "# Store\n",
    "data = {\"model\": lgb_reg, \"le_car\": le_car, \"le_body\": le_body, \"le_engType\":le_engType , \"le_drive\":le_drive}\n",
    "with open('models/model.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dcfe8",
   "metadata": {
    "id": "e79dcfe8",
    "outputId": "8bac1061-0154-441a-cf76-1501b0c4f831"
   },
   "outputs": [],
   "source": [
    "# Read\n",
    "with open('models/model.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "model = data[\"model\"]\n",
    "le_car = data[\"le_car\"]\n",
    "le_body = data[\"le_body\"]\n",
    "le_engType = data[\"le_engType\"]\n",
    "le_drive = data[\"le_drive\"]\n",
    "\n",
    "y_pred_sample = model.predict(X_sample)\n",
    "print(\"Your car estimated price is: \",\"${:,.02f}\".format(y_pred_sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('car_ad_display_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D4cJqsLXcGRy",
   "metadata": {
    "id": "D4cJqsLXcGRy"
   },
   "source": [
    "## Explainability AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jn2Pyq77cGRy",
   "metadata": {
    "id": "jn2Pyq77cGRy"
   },
   "source": [
    "As an excellent data scientist, we cannot conclude our work without understanding how the model works. In this section of the project, we will apply SHAP as a technique to understand, debug and explain our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aLk7hSOzcGRy",
   "metadata": {
    "id": "aLk7hSOzcGRy"
   },
   "source": [
    "### Global explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bcod9PfpcGRy",
   "metadata": {
    "id": "Bcod9PfpcGRy"
   },
   "source": [
    "#### EX9: Train a Shap explainer and calculate the shap_values object for the X_test dataset. Print the shap values object of the first sample of X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W5zplQ8vcGRy",
   "metadata": {
    "id": "W5zplQ8vcGRy",
    "outputId": "82806ff2-e65a-4bec-a20a-7b06506adb82"
   },
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "display(X_test)\n",
    "print(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9e0dea",
   "metadata": {},
   "source": [
    "#### EX10: Which is the average price cost prediction for all cars?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68606b16",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The ```base_values``` attribute holds the average prediction for any car: in this case $14,393.64 on average\n",
    "\n",
    "Note: ($ is in local currency, not necessarily USD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pSbWwmNNcGRy",
   "metadata": {
    "id": "pSbWwmNNcGRy"
   },
   "source": [
    "#### Let's plot the summary plot and bar plot for global explainability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4RhjPooZcGRy",
   "metadata": {
    "id": "4RhjPooZcGRy",
    "outputId": "259459cb-7ec5-44a6-f63c-070502e15c6e"
   },
   "outputs": [],
   "source": [
    "#Global Explainability\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpPgPJ4QcGRy",
   "metadata": {
    "id": "wpPgPJ4QcGRy",
    "outputId": "d5b5bb84-ec32-475d-d8c0-352b75d45838"
   },
   "outputs": [],
   "source": [
    "#Plot var: built from column 1 of all shap_values\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b1527",
   "metadata": {},
   "source": [
    "#### EX11: Which are your insights?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5fcea",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "The features that import the most (in descending order) for this model can be seen in the previous barplot. That means that probably if we were to remove, for instance, `body` from the analysis, the results would not change drastically. However if we were to change `year`, the results would change drastically, probably worsening significantly our model's capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "umupYXJccGRz",
   "metadata": {
    "id": "umupYXJccGRz"
   },
   "source": [
    "#### Let's do deep dive in the variables `Mileage`, `engV` and `year`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "li8kQ1EOcGRz",
   "metadata": {
    "id": "li8kQ1EOcGRz",
    "outputId": "078c4995-d9d9-44c5-f912-90bd0748c5db"
   },
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,\"mileage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-pfT4cThcGRz",
   "metadata": {
    "id": "-pfT4cThcGRz",
    "outputId": "9024ff2d-bf79-4d17-c11a-d6baff90fb02"
   },
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,\"engV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gyXM_LWGcGRz",
   "metadata": {
    "id": "gyXM_LWGcGRz",
    "outputId": "7516e01e-7901-413b-c457-b025a0105595"
   },
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,\"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5517c7fc",
   "metadata": {},
   "source": [
    "#### EX12: What are the most relevant insights abour the evolution of the features' values and their Shap values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97341009",
   "metadata": {},
   "source": [
    "#### **Solution:**\n",
    "We can see that `mileage` is very important, but only in a small portion of the range. Once the mileage gets past 100 (probably thousand) miles the feature loses importance, meaning that the impact of the feature miles does not change the output significantly in the range `[100-600]`. That becomes especially true after `300` miles.\n",
    "\n",
    "`EngV` importance is pretty linear, having its breakpoint at around `3L`. If below, the impact is negative, and positive otherwise.\n",
    "\n",
    "`Year`'s importance seems to be exponential. Cars manufactured before `2010`'s have quite a negative (but similar) impact. After that, manufacturing year's importance seems to be exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fYocnoSncGRz",
   "metadata": {
    "id": "fYocnoSncGRz"
   },
   "source": [
    "#### Let's analyze the relationship of the variables `engV` and `year` and their Shap values according to the value of `mileage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4AUYOX2hcGRz",
   "metadata": {
    "id": "4AUYOX2hcGRz",
    "outputId": "94a681a2-4729-47d0-80f8-1844b6dae7d0"
   },
   "outputs": [],
   "source": [
    "#Let's analyze the evolution of Shap values of engV based on mileage\n",
    "shap.dependence_plot(\"engV\", shap_values.values, X_test, interaction_index= \"mileage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SB8PQvX0cGRz",
   "metadata": {
    "id": "SB8PQvX0cGRz",
    "outputId": "3e2b43c6-4a42-45be-9ec2-9f04d58d5f45"
   },
   "outputs": [],
   "source": [
    "#Let's analyze the evolution of Shap values of engV based on mileage\n",
    "shap.dependence_plot(\"year\", shap_values.values, X_test, interaction_index= \"mileage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd36335",
   "metadata": {},
   "source": [
    " #### EX13: What are the most relevant insights about the evolution of the features' values and their Shap values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa102c6",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Manufacturing year seems to be quite negatively correlated with mileage (as can be seen in the heatmap above). Also having higher engine volume seems to be correlated with higher mileage, but not as importantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gmkpo6tYcGRz",
   "metadata": {
    "id": "gmkpo6tYcGRz"
   },
   "source": [
    "### Local explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112g_iwCcGRz",
   "metadata": {
    "id": "112g_iwCcGRz"
   },
   "source": [
    "Local explainability facilitates the understanding of the prediction for some particular cases. In other words, XAI closes to a personalized prediction explainability. Let's use the first sample of X_test for the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8IHlzDHfcGRz",
   "metadata": {
    "id": "8IHlzDHfcGRz"
   },
   "source": [
    "#### Using the waterfall, force and decision plots, we can explain how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Eb3-H3CVcGRz",
   "metadata": {
    "id": "Eb3-H3CVcGRz",
    "outputId": "558a288a-6d6b-4c32-f8f9-38080496f4a2"
   },
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2tpqXypkcGRz",
   "metadata": {
    "id": "2tpqXypkcGRz",
    "outputId": "9c75d234-ca98-49c2-a323-cb75bebe61a3"
   },
   "outputs": [],
   "source": [
    "shap.plots.force(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FXRqKjjNcGRz",
   "metadata": {
    "id": "FXRqKjjNcGRz",
    "outputId": "e31a75c0-e2f5-4c2d-e3c9-df453d70cd63"
   },
   "outputs": [],
   "source": [
    "shap.decision_plot(shap_values[0].base_values,shap_values[0].values, X_test.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86b44b",
   "metadata": {},
   "source": [
    "Given this example (`year=1990, engV=1.8, ...`) we can see how each variable affects the final prediction: we can see that most variables affect negatively the price (in blue), which gets reduced from the mean prediction ($14,393.64) down to its actual prediction ($2,981.22). We can see how the year reduces around $8,000, engV around $1,500, etc. These plots give a good sense on why the predicted value is what it is, and the reasons behind that."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
